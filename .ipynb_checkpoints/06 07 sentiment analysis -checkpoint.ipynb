{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review  sentiment\n",
      "0  In 1974, the teenager Martha Moxley (Maggie Gr...          1\n",
      "1  OK... so... I really like Kris Kristofferson a...          0\n",
      "2  ***SPOILER*** Do not read this, if you think a...          0\n",
      "3  hi for all the people who have seen this wonde...          1\n",
      "4  I recently bought the DVD, forgetting just how...          0\n",
      "\n",
      "I saw this movie on the strength of the single positive review and I can only imagine that guy is a shill.<br /><br />The acting of the female lead is actually quite good, but the entire film is just so excruciatingly boring I could hardly bear to sit through it. This is the very definition of dullness.<br /><br />So far, this film is rated as 8 out of 10 on 7 votes. That must mean the director, director's girlfriend, producer, actress and drinking buddies have given their own film a 10.<br /><br />For the rest of you, who simply want to be entertained or enjoy a good story, avoid this.<br /><br />This man on the street shall give it a 2 out of 10.<br /><br />FDA note: while this movie can be used as an aide to obtaining a good nights sleep, no medicinal value is implied or offered.\n",
      "\n",
      "I saw this movie on the strength of the single positive review and I can only imagine that guy is a shill.<br /><br />The acting of the female lead is actually quite good, but the entire film is just so excruciatingly boring I could hardly bear to sit through it. This is the very definition of dullness.<br /><br />So far, this film is rated as 8 out of 10 on 7 votes. That must mean the director, director's girlfriend, producer, actress and drinking buddies have given their own film a 10.<br /><br />For the rest of you, who simply want to be entertained or enjoy a good story, avoid this.<br /><br />This man on the street shall give it a 2 out of 10.<br /><br />FDA note: while this movie can be used as an aide to obtaining a good nights sleep, no medicinal value is implied or offered.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "df = pd.read_csv('./movie_data.csv')\n",
    "print df.head()\n",
    "print\n",
    "print df['review'].head(20)[15]\n",
    "print \n",
    "print df.loc[15,'review']\n",
    "\n",
    "\n",
    "count = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 5)\t1\n",
      "  (0, 3)\t1\n",
      "  (0, 1)\t1\n",
      "  (0, 2)\t1\n",
      "  (1, 5)\t1\n",
      "  (1, 1)\t1\n",
      "  (1, 6)\t1\n",
      "  (1, 4)\t1\n",
      "  (2, 5)\t2\n",
      "  (2, 3)\t1\n",
      "  (2, 1)\t2\n",
      "  (2, 2)\t1\n",
      "  (2, 6)\t1\n",
      "  (2, 4)\t1\n",
      "  (2, 0)\t1\n",
      "{u'and': 0, u'weather': 6, u'sweet': 4, u'sun': 3, u'is': 1, u'the': 5, u'shining': 2}\n",
      "[[0 1 1 1 0 1 0]\n",
      " [0 1 0 0 1 1 1]\n",
      " [1 2 1 1 1 2 1]]\n"
     ]
    }
   ],
   "source": [
    "docs = np.array([\n",
    "'The sun is shining',\n",
    "'The weather is sweet',\n",
    "'The sun is shining and the weather is sweet'])\n",
    "bag = count.fit_transform(docs)\n",
    "print bag\n",
    "print(count.vocabulary_)\n",
    "print(bag.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.    0.43  0.56  0.56  0.    0.43  0.  ]\n",
      " [ 0.    0.43  0.    0.    0.56  0.43  0.56]\n",
      " [ 0.4   0.48  0.31  0.31  0.31  0.48  0.31]]\n"
     ]
    }
   ],
   "source": [
    "#tf-idf: term frequency - inverse document frequency ( bag of words model)\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf = TfidfTransformer()\n",
    "np.set_printoptions(precision=2)\n",
    "print(tfidf.fit_transform(count.fit_transform(docs)).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zation my vote is seven title brazil not available\n",
      "zation my vote is seven title brazil not available\n",
      "this is a test \n"
     ]
    }
   ],
   "source": [
    "# cleaning the text datab\n",
    "df.loc[0, 'review'][-50:]\n",
    "import re\n",
    "def preprocessor(text):\n",
    "    text = re.sub('<[^>]*>', '', text)\n",
    "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text)\n",
    "    text = re.sub('[\\W]+', ' ', text.lower())\n",
    "    return text\n",
    "\n",
    "print preprocessor(df.loc[0, 'review'][-50:])\n",
    "print preprocessor(\"</a>This :) is :( a test :-)!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zation my vote is seven title brazil not available\n"
     ]
    }
   ],
   "source": [
    "df['review'] = df['review'].apply(preprocessor)\n",
    "print df.loc[0, 'review'][-50:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['runners', 'like', 'running', 'and', 'thus', 'they', 'run']\n",
      "[u'runner', u'like', u'run', u'and', u'thu', u'they', u'run']\n"
     ]
    }
   ],
   "source": [
    "#split the text corpora into individual elements \n",
    "# method 1\n",
    "def tokenizer(text):\n",
    "    return text.split()\n",
    "print tokenizer('runners like running and thus they run')\n",
    "#method 2 using Porter stemmer algorithm developed by Martin F. Porter in 1979\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "porter = PorterStemmer()\n",
    "def tokenizer_porter(text):\n",
    "    return [porter.stem(word) for word in text.split()]\n",
    "print tokenizer_porter('runners like running and thus they run')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'i', u'me', u'my', u'myself', u'we', u'our', u'ours', u'ourselves', u'you', u'your', u'yours', u'yourself', u'yourselves', u'he', u'him', u'his', u'himself', u'she', u'her', u'hers', u'herself', u'it', u'its', u'itself', u'they', u'them', u'their', u'theirs', u'themselves', u'what', u'which', u'who', u'whom', u'this', u'that', u'these', u'those', u'am', u'is', u'are', u'was', u'were', u'be', u'been', u'being', u'have', u'has', u'had', u'having', u'do', u'does', u'did', u'doing', u'a', u'an', u'the', u'and', u'but', u'if', u'or', u'because', u'as', u'until', u'while', u'of', u'at', u'by', u'for', u'with', u'about', u'against', u'between', u'into', u'through', u'during', u'before', u'after', u'above', u'below', u'to', u'from', u'up', u'down', u'in', u'out', u'on', u'off', u'over', u'under', u'again', u'further', u'then', u'once', u'here', u'there', u'when', u'where', u'why', u'how', u'all', u'any', u'both', u'each', u'few', u'more', u'most', u'other', u'some', u'such', u'no', u'nor', u'not', u'only', u'own', u'same', u'so', u'than', u'too', u'very', u's', u't', u'can', u'will', u'just', u'don', u'should', u'now', u'd', u'll', u'm', u'o', u're', u've', u'y', u'ain', u'aren', u'couldn', u'didn', u'doesn', u'hadn', u'hasn', u'haven', u'isn', u'ma', u'mightn', u'mustn', u'needn', u'shan', u'shouldn', u'wasn', u'weren', u'won', u'wouldn']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[u'runner', u'like', u'run', u'run', u'lot']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stop-word removal.\n",
    "import nltk\n",
    "#nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "print stop\n",
    "[w for w in tokenizer_porter('a runner likes running and runs a lot')[-10:] if w not in stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# training a logistic regression\n",
    "X_train = df.loc[:25000, 'review'].values\n",
    "y_train = df.loc[:25000, 'sentiment'].values\n",
    "X_test = df.loc[25000:, 'review'].values\n",
    "y_test = df.loc[25000:, 'sentiment'].values\n",
    "print type(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(strip_accents=None,lowercase=False,preprocessor=None)\n",
    "param_grid = [{'vect__ngram_range': [(1,1)],\n",
    " 'vect__stop_words': [stop, None],\n",
    " 'vect__tokenizer': [tokenizer, tokenizer_porter],\n",
    "'clf__penalty': ['l1', 'l2'],\n",
    "'clf__C': [1.0, 10.0, 100.0]},\n",
    " {'vect__ngram_range': [(1,1)],\n",
    " 'vect__stop_words': [stop, None],\n",
    " 'vect__tokenizer': [tokenizer,\n",
    " tokenizer_porter],\n",
    " 'vect__use_idf':[False],\n",
    " 'vect__norm':[None],\n",
    " 'clf__penalty': ['l1', 'l2'],\n",
    " 'clf__C': [1.0, 10.0, 100.0]}\n",
    " ]\n",
    "lr_tfidf = Pipeline([('vect', tfidf), ('clf', LogisticRegression(random_state=0))])\n",
    "gs_lr_tfidf = GridSearchCV(lr_tfidf, param_grid,scoring='accuracy', cv=5, verbose=1, n_jobs=-1)\n",
    "gs_lr_tfidf.fit(X_train, y_train)\n",
    "print('Best parameter set: %s ' % gs_lr_tfidf.best_params_)\n",
    "print('CV Accuracy: %.3f' % gs_lr_tfidf.best_score_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
