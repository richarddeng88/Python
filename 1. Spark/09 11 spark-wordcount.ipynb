{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "theRDD = sc.textFile(\"hdfs:/user/cloudera/data/shakespeare.txt\")\n",
    "wordCounts = theRDD\n",
    "            .flatMap(lambda line: line.split(\" \"))\n",
    "            .map(lambda word: (word, 1))\n",
    "            .reduceByKey(lambda a, b: a+b,1)\n",
    "            .map(lambda a :(a[1],a[0]))\n",
    "            .sortByKey(0,1)\n",
    "            .filter(lambda a : a[1]!=\"\")\n",
    "wordCounts.take(5)\n",
    "wrodCounts.saveAsTextFile('hdfs:/user/cloudera/spark-word-count/output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(23242, 'the'), (19540, 'I'), (18297, 'and'), (15623, 'to'), (15544, 'of')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theRDD = sc.textFile(\"hdfs:/user/cloudera/data/shakespeare.txt\")\n",
    "wordCounts = theRDD.\\\n",
    "            flatMap(lambda line: line.split(\" \")).\\\n",
    "            map(lambda word: (word, 1)).\\\n",
    "            reduceByKey(lambda a, b: a+b,1).\\\n",
    "            map(lambda a :(a[1],a[0])).\\\n",
    "            sortByKey(0,1).\\\n",
    "            filter(lambda a : a[1]!=\"\")\n",
    "wordCounts.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'wordConts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-c92b78102237>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwordConts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'wordConts' is not defined"
     ]
    }
   ],
   "source": [
    "type(wordConts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1 read file\n",
    "# Spark Context - sc, is the main entry point for accessing Spark in Python. the textFile() method reads the txt file \n",
    "## from HDFS into the RDD (Resilient Distributed Dataset) with each line in the article being an element in the RDD\n",
    "## collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This is the 100th Etext file presented by Project Gutenberg, and',\n",
       " 'is presented in cooperation with World Library, Inc., from their',\n",
       " 'Library of the Future and Shakespeare CDROMS.  Project Gutenberg',\n",
       " 'often releases Etexts that are NOT placed in the Public Domain!!',\n",
       " '']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = sc.textFile(\"hdfs:/user/cloudera/data/shakespeare.txt\")\n",
    "lines.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.rdd.RDD"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2. flatmap\n",
    "# Split each line into words: The flatMap() method iterates over every line in the RDD, and lambda line : line.split(\" \")\n",
    "# The lambda notation is an anonymous function in Python, i.e., a function de·ÄÅned withoutusing a name. \n",
    "## is executed on each line. in this case, lambda takes a single argument, line, and calls split(\" \") which splits \n",
    "## the line into an array words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This',\n",
       " 'is',\n",
       " 'the',\n",
       " '100th',\n",
       " 'Etext',\n",
       " 'file',\n",
       " 'presented',\n",
       " 'by',\n",
       " 'Project',\n",
       " 'Gutenberg,']"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = lines.flatMap(lambda line : line.split(\" \"))\n",
    "words.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 3. tuples\n",
    "# Assign initial count value to each word, creating tuples for each word with an initial count of 1. \n",
    "## we have a one-to-one mapping between the input words and output tuples. I\n",
    "## The map() method iterates over every word in the words RDD, and the lambda expression creates a tuple with the word and a value of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('This', 1), ('is', 1), ('the', 1), ('100th', 1), ('Etext', 1)]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuples = words.map(lambda word: (word , 1))\n",
    "tuples.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 4. reducekey\n",
    "#Sum all word count values. \n",
    "#The reduceByKey() method calls the lambda function for all the tuples with the same word.\n",
    "# the lambda function has two arguments, a and b, which are the count values in two tuples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('', 517065),\n",
       " ('VENTIDIUS', 3),\n",
       " ('Stockfish,', 1),\n",
       " ('Corin,', 2),\n",
       " ('Begin', 6)]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = tuples.reduceByKey(lambda a, b : (a+b),1)\n",
    "counts.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(517065, ''),\n",
       " (3, 'VENTIDIUS'),\n",
       " (1, 'Stockfish,'),\n",
       " (2, 'Corin,'),\n",
       " (6, 'Begin')]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swap = counts.map(lambda a :(a[1],a[0]))\n",
    "swap.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(517065, ''), (23242, 'the'), (19540, 'I'), (18297, 'and'), (15623, 'to')]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sort = swap.sortByKey(0,1)\n",
    "sort.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(23242, 'the'), (19540, 'I'), (18297, 'and'), (15623, 'to'), (15544, 'of')]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fil = sort.filter(lambda a : a[1]!=\"\")\n",
    "fil.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 5. write file\n",
    "#Write word counts to text file in HDFS. We can write the counts RDD to HDFS:\n",
    "# The coalesce() method combines all the RDD partitions into a single partition since we want a single\n",
    "#output file, and saveAsTextFile() writes the RDD to the specified location."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "counts.coalesce(1).saveAsTextFile('hdfs:/user/cloudera/spark-word-count/output')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
